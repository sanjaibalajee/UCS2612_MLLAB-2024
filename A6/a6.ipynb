{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#In-built K Means Methods"
      ],
      "metadata": {
        "id": "WYLfQhqWVgfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byzQpqm2_3K3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(\"\\n\\nThe Size of The Training Dataset : \",train_df.shape)\n",
        "print(\"\\nThe Size of The Training Dataset : \",test_df.shape)\n",
        "print(train_df)\n",
        "print(\"The Missing Values in The Training Dataset\\n\\n\",train_df.isnull().sum())\n",
        "print(\"The Missing Values in The Testing Dataset\\n\\n\",test_df.isnull().sum())\n",
        "print(train_df.columns)\n",
        "x=train_df.drop(columns={\"Activity\"})\n",
        "y=train_df[\"Activity\"]\n",
        "# Load the data\n",
        "train_df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "m5EyHkATRdwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection and prepare the dataset\n",
        "x = train_df.drop(columns=[\"Activity\"])\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# Initialize lists to store results\n",
        "k_values = list(range(2, 11))\n",
        "elbow_scores = []\n",
        "silhouette_scores = []\n",
        "davies_bouldin_scores = []"
      ],
      "metadata": {
        "id": "Ig_81Rp5Re_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding optimal k value using Elbow method and Silhouette Score"
      ],
      "metadata": {
        "id": "LnjkPFGoVuRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow Method\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "    kmeans.fit(x_scaled)\n",
        "    elbow_scores.append(kmeans.inertia_)\n",
        "\n",
        "# Silhouette Score and Davies-Bouldin Index\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "    kmeans.fit(x_scaled)\n",
        "    silhouette_scores.append(silhouette_score(x_scaled, kmeans.labels_))\n",
        "    davies_bouldin_scores.append(davies_bouldin_score(x_scaled, kmeans.labels_))\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Elbow Method Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(k_values, elbow_scores, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('WCSS (Elbow Score)')\n",
        "plt.title('Elbow Method')\n",
        "\n",
        "# Silhouette Score and Davies-Bouldin Index Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(k_values, silhouette_scores, marker='o', label='Silhouette Score')\n",
        "plt.plot(k_values, davies_bouldin_scores, marker='o', label='Davies-Bouldin Index')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Silhouette Score and Davies-Bouldin Index')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-TFF-Q8XRjhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = SelectKBest(score_func=f_classif, k=5)\n",
        "fit = test.fit(x, y)\n",
        "np.set_printoptions(precision=10)\n",
        "\n",
        "features = fit.transform(x)\n",
        "\n",
        "selected_indices = fit.get_support(indices=True)\n",
        "\n",
        "selected_feature_names = x.columns[selected_indices]\n",
        "\n",
        "print(\"Selected feature names : \\n\")\n",
        "print(selected_feature_names)\n",
        "train_df1 = train_df[selected_feature_names].copy()\n",
        "test_df1 = test_df[selected_feature_names].copy()\n",
        "print(\"\\nAfter Feature Selection The Shape of The Training Dataset : \",train_df1.shape)\n",
        "print(\"After Feature Selection The Shape of The Testing Dataset  : \",test_df1.shape)\n",
        "n_clusters = 3\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "kmeans.fit(train_df1)\n",
        "train_clusters = kmeans.predict(train_df1)\n",
        "test_clusters = kmeans.predict(test_df1)\n",
        "cluster_centroids = kmeans.cluster_centers_\n",
        "silhouette_avg11 = silhouette_score(train_df1, train_clusters)\n",
        "silhouette_avg12 = silhouette_score(test_df1, test_clusters)\n",
        "print(f\"Silhouette Score ( Training dataset )   : {silhouette_avg11}\")\n",
        "print(f\"Silhouette Score ( Testing dataset  )   : {silhouette_avg12}\")\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_data = train_df1[train_clusters == cluster]\n",
        "\n",
        "    plt.scatter(cluster_data['tGravityAcc-mean()-X'], cluster_data['tGravityAcc-max()-X'], label=f'Cluster {cluster}')\n",
        "\n",
        "plt.scatter(cluster_centroids[:, 0], cluster_centroids[:, 1], marker='x', color='black', s=100, label='Centroids')\n",
        "\n",
        "plt.title('Clustering Results')\n",
        "plt.xlabel('GravityAcc-mean()-X')\n",
        "plt.ylabel('tGravityAcc-max()-X')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "ridge = Ridge(alpha=1.0)\n",
        "select_from_model = SelectFromModel(ridge, max_features=8)\n",
        "select_from_model.fit(x, y_encoded)\n",
        "features_selected = select_from_model.transform(x)\n",
        "selected_indices = select_from_model.get_support(indices=True)\n",
        "selected_feature_names = x.columns[selected_indices]\n",
        "print(\"Selected feature names : \\n\")\n",
        "print(selected_feature_names)\n",
        "train_df2 = train_df[selected_feature_names].copy()\n",
        "test_df2 = test_df[selected_feature_names].copy()\n",
        "n_clusters = 3\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "kmeans.fit(train_df2)\n",
        "train_clusters = kmeans.predict(train_df2)\n",
        "test_clusters = kmeans.predict(test_df2)\n",
        "cluster_centroids = kmeans.cluster_centers_\n",
        "silhouette_avg21 = silhouette_score(train_df2, train_clusters)\n",
        "silhouette_avg22 = silhouette_score(test_df2, test_clusters)\n",
        "print(f\"Silhouette Score ( Training dataset )   : {silhouette_avg21}\")\n",
        "print(f\"Silhouette Score ( Testing dataset  )   : {silhouette_avg22}\")\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_data = train_df2[train_clusters == cluster]\n",
        "\n",
        "    plt.scatter(cluster_data['tBodyAcc-std()-X'], cluster_data['tBodyAcc-sma()'], label=f'Cluster {cluster}')\n",
        "\n",
        "plt.scatter(cluster_centroids[:, 0], cluster_centroids[:, 1], marker='x', color='black', s=100, label='Centroids')\n",
        "\n",
        "plt.title('Clustering Results')\n",
        "plt.xlabel('GravityAcc-mean()-X')\n",
        "plt.ylabel('tGravityAcc-max()-X')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "pca = PCA(n_components=11)\n",
        "\n",
        "pca.fit(x)\n",
        "\n",
        "selected_feature_indices = pca.components_\n",
        "\n",
        "selected_feature_names = [x.columns[i] for i in range(len(selected_feature_indices))]\n",
        "\n",
        "print(\"Selected feature names:\")\n",
        "print(selected_feature_names)\n",
        "train_df3 = train_df[selected_feature_names].copy()\n",
        "test_df3 = test_df[selected_feature_names].copy()\n",
        "n_clusters = 3\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "kmeans.fit(train_df3)\n",
        "train_clusters = kmeans.predict(train_df3)\n",
        "test_clusters = kmeans.predict(test_df3)\n",
        "cluster_centroids = kmeans.cluster_centers_\n",
        "silhouette_avg31 = silhouette_score(train_df3, train_clusters)\n",
        "silhouette_avg32 = silhouette_score(test_df3, test_clusters)\n",
        "print(f\"Silhouette Score ( Training dataset )   : {silhouette_avg31}\")\n",
        "print(f\"Silhouette Score ( Testing dataset  )   : {silhouette_avg32}\")\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_data = train_df3[train_clusters == cluster]\n",
        "\n",
        "    plt.scatter(cluster_data['tBodyAcc-mean()-X'], cluster_data['tBodyAcc-mean()-Y'], label=f'Cluster {cluster}')\n",
        "\n",
        "plt.scatter(cluster_centroids[:, 0], cluster_centroids[:, 1], marker='x', color='black', s=100, label='Centroids')\n",
        "\n",
        "plt.title('Clustering Results')\n",
        "plt.xlabel('GravityAcc-mean()-X')\n",
        "plt.ylabel('tGravityAcc-max()-X')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Z74ERH9Rrhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "train_pca = pca.fit_transform(x_scaled)\n",
        "\n",
        "# Scatter Plot for Training Data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(train_pca[:, 0], train_pca[:, 1], c=train_clusters, cmap='viridis', s=50, alpha=0.5)\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', s=200, c='red', label='Centroids')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.title('KMeans Clustering of Training Data (PCA)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sGu5idyVR0qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User-defined K Means Methods"
      ],
      "metadata": {
        "id": "SfYklawBVpHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "def assign_clusters(X, centroids):\n",
        "    clusters = np.zeros(len(X))\n",
        "    for i in range(len(X)):\n",
        "        distances = [euclidean_distance(X[i], centroid) for centroid in centroids]\n",
        "        cluster = np.argmin(distances)\n",
        "        clusters[i] = cluster\n",
        "    return clusters\n",
        "\n",
        "def update_centroids(X, clusters, k):\n",
        "    centroids = np.zeros((k, X.shape[1]))\n",
        "    for i in range(k):\n",
        "        cluster_points = X[clusters == i]\n",
        "        centroids[i] = np.mean(cluster_points, axis=0)\n",
        "    return centroids\n",
        "\n",
        "def k_means(X, k, max_iters, plot_steps=False):\n",
        "    centroids = X[np.random.choice(len(X), k, replace=False)]\n",
        "    if plot_steps:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
        "        plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', color='red', label='Initial Centroids')\n",
        "        plt.title('Initial Centroids')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    for iter in range(max_iters):\n",
        "        clusters = assign_clusters(X, centroids)\n",
        "        new_centroids = update_centroids(X, clusters, k)\n",
        "        if plot_steps:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.5)\n",
        "            plt.scatter(new_centroids[:, 0], new_centroids[:, 1], marker='x', color='red', label='Updated Centroids')\n",
        "            plt.title(f'Iteration {iter + 1}')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        if np.array_equal(new_centroids, centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters, centroids\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "y2T0yiNIVffw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "train_data.drop(columns=['subject'], inplace=True)\n",
        "test_data.drop(columns=['subject'], inplace=True)\n",
        "\n",
        "# Convert class labels to numerical values\n",
        "class_mapping = {'WALKING': 0, 'WALKING_UPSTAIRS': 1, 'WALKING_DOWNSTAIRS': 2, 'SITTING': 3, 'STANDING': 4, 'LAYING': 5}\n",
        "train_data['Activity'] = train_data['Activity'].map(class_mapping)\n",
        "test_data['Activity'] = test_data['Activity'].map(class_mapping)\n",
        "\n",
        "# Extract features and labels\n",
        "X_train = train_data.drop(columns=['Activity']).values\n",
        "y_train = train_data['Activity'].values\n",
        "X_test = test_data.drop(columns=['Activity']).values\n",
        "y_test = test_data['Activity'].values\n",
        "\n",
        "# Perform k-means clustering with intermediate plots\n",
        "k = 3\n",
        "max_iters = 15\n",
        "clusters, centroids = k_means(X_train, k, max_iters, plot_steps=True)\n",
        "\n",
        "# Map cluster labels to class labels\n",
        "cluster_mapping = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
        "y_pred = np.array([cluster_mapping[int(cluster)] for cluster in clusters])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = calculate_accuracy(y_train, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Scatter plot for train data with final clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=clusters, cmap='viridis', alpha=0.5)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', color='red', label='Final Centroids')\n",
        "plt.title('Train Data Scatter Plot with Final Clusters')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TmLAXaCjV-In"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}